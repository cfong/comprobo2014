{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.optimize import minimize\n",
      "\n",
      "def riccati(v_asvector, A, B, Q, F, gamma):\n",
      "    V = v_asvector.reshape(Q.shape)\n",
      "    V = (np.triu(V)+np.triu(V).T)/2.0\n",
      "    res = V - Q - gamma*A.T.dot(V-gamma*V.dot(B).dot(np.linalg.inv(F+B.T.dot(V).dot(B))).dot(B.T).dot(V.T)).dot(A)\n",
      "    return np.sum(res**2)\n",
      "\n",
      "d = .01\n",
      "delta_t = .1\n",
      "gamma = 0.99\n",
      "\n",
      "A = np.array([[1.0, delta_t],\n",
      "              [0, 1.0-d*delta_t]])\n",
      "B = np.array([[0],\n",
      "              [delta_t]])\n",
      "Q = np.array([[1.0,0],\n",
      "              [0,1.0]])\n",
      "F = np.array([[1.0]])\n",
      "\n",
      "v_asvector_0 = np.array([18.3396, 10.8995, 10.8995,18.7993])\n",
      "\n",
      "res = minimize(riccati,v_asvector_0,(A,B,Q,F,gamma),options={'maxiter' : 4000})\n",
      "v_asvector_final = res.x\n",
      "\n",
      "print riccati(v_asvector_0,A,B,Q,F,gamma)\n",
      "print riccati(v_asvector_final,A,B,Q,F,gamma)\n",
      "\n",
      "V = v_asvector_final.reshape(Q.shape)\n",
      "V = (np.triu(V)+np.triu(V).T)/2.0\n",
      "K = np.linalg.inv(F+B.T.dot(V).dot(B)).dot(B.T).dot(V.T).dot(A)\n",
      "\n",
      "print K\n",
      "print V"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import deepcopy\n",
      "\n",
      "def run_trajectory(x,K):\n",
      "    trajectory = np.zeros((0,3))\n",
      "    n_time_points = 200\n",
      "    t_vals = np.array(range(n_time_points))*delta_t\n",
      "    total_reward = 0\n",
      "    for t in range(n_time_points-1):\n",
      "        u = -K.dot(x)\n",
      "        new_point = np.array([x[0],x[1],u]).T\n",
      "        total_reward += gamma**t*(-0.5*x.T.dot(Q).dot(x)-0.5*u.T.dot(F).dot(u))\n",
      "        trajectory = np.vstack((trajectory,new_point))\n",
      "        x = A.dot(x)+B.dot(u)\n",
      "\n",
      "    new_point = np.array([x[0],x[1],0]).T\n",
      "    trajectory = np.vstack((trajectory,new_point))\n",
      "    return (t_vals,trajectory,total_reward)\n",
      "\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "x = np.array([[2.0,0.0]]).T\n",
      "(t_vals,trajectory,total_reward) = run_trajectory(x,K)\n",
      "\n",
      "plt.plot(t_vals,trajectory)\n",
      "plt.xlabel('time (s)')\n",
      "plt.legend(['x','x dot','u'])\n",
      "plt.show()\n",
      "\n",
      "print 'Total reward: %f'%total_reward\n",
      "\n",
      "# tweak K\n",
      "for i in range(K.shape[0]):\n",
      "    for j in range(K.shape[1]):\n",
      "        K_new = deepcopy(K)\n",
      "        K_new[i,j] += .05\n",
      "        (t_vals,trajectory,total_reward) = run_trajectory(x,K_new)\n",
      "        print 'Total reward: %f'%total_reward\n",
      "        \n",
      "        K_new = deepcopy(K)\n",
      "        K_new[i,j] -= .05\n",
      "        (t_vals,trajectory,total_reward) = run_trajectory(x,K_new)\n",
      "        print 'Total reward: %f'%total_reward"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}